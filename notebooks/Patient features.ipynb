{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theo/kaggle/pulmonary_embolism/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import pydicom\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.logger import *\n",
    "from data.dataset import *\n",
    "from data.transforms import get_transfos\n",
    "\n",
    "from model_zoo.models import define_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH + \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "splits = list(gkf.split(X=df, y=df, groups=df['StudyInstanceUID']))\n",
    "\n",
    "\n",
    "fold_idx = np.zeros(len(df))\n",
    "for i, (train_idx, val_idx) in enumerate(splits):\n",
    "    fold_idx[val_idx] = i\n",
    "df['fold'] = fold_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for feature extraction\n",
    "    \"\"\"\n",
    "    def __init__(self, path, transforms=None): \n",
    "        self.path = path\n",
    "        self.img_paths = sorted(os.listdir(path))\n",
    "        \n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.path + self.img_paths[idx])\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)[\"image\"]\n",
    "\n",
    "        return image, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jpg_path = IMG_PATH + \"6897fa9de148/2bfbb7fd2e8b/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos(augment=False)\n",
    "# transforms = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PatientDataset(jpg_path, transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transforms is None:\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(dataset_jpg[0][0])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(dataset_jpg[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [IMG_PATH + f\"{study}/{series}/\" for study, series in df[['StudyInstanceUID', 'SeriesInstanceUID']].values]\n",
    "df['path'] = paths\n",
    "unique_df = df[['path', 'StudyInstanceUID', 'SeriesInstanceUID', 'fold']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_PATH = \"../logs/weights/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.models import define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.torch_utils import load_model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [f for f in sorted(os.listdir(CP_PATH)) if \"efficientnet\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "\n",
      " -> Loading weights from ../logs/weights/efficientnet-b3__0.pt\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "\n",
      " -> Loading weights from ../logs/weights/efficientnet-b3__1.pt\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "\n",
      " -> Loading weights from ../logs/weights/efficientnet-b3__2.pt\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "\n",
      " -> Loading weights from ../logs/weights/efficientnet-b3__3.pt\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "\n",
      " -> Loading weights from ../logs/weights/efficientnet-b3__4.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for weight in weights:\n",
    "    model = define_model('efficientnet-b3').cuda()\n",
    "    model = load_model_weights(model, CP_PATH + weight)\n",
    "    models.append(model)\n",
    "    \n",
    "# models = []\n",
    "\n",
    "# for weight in weights:\n",
    "#     model = define_model('resnext50_32x4d').cuda()\n",
    "#     model = load_model_weights(model, CP_PATH + weight)\n",
    "#     models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def extract_features(model, dataset, batch_size=4):\n",
    "    model.eval()\n",
    "    fts = np.empty((0, model.nb_ft))\n",
    "    preds = np.empty(0)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, drop_last=False\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader:\n",
    "            y, ft = model.extract_ft(x.cuda())\n",
    "            fts = np.concatenate([fts, ft.detach().cpu().numpy()])\n",
    "            preds = np.concatenate([preds, torch.sigmoid(y).detach().cpu().numpy()])\n",
    "\n",
    "    return preds, fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = FEATURES_PATH + \"b3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b33fb4190b4e55868362b67a821e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=7279.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for path, study, series, fold in tqdm(unique_df.values):\n",
    "    dataset = PatientDataset(path, transforms)\n",
    "    \n",
    "    preds, features = extract_features(models[int(fold)], dataset, batch_size=32)\n",
    "    \n",
    "    np.save(f\"{SAVE_PATH}/features_{'_'.join(path.split('/')[-3:-1])}.npy\" , features)\n",
    "    np.save(f\"{SAVE_PATH}/preds_{'_'.join(path.split('/')[-3:-1])}.npy\" , preds)\n",
    "\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
